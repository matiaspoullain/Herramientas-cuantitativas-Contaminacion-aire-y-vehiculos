{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4-Modelo NO2-vehiculos.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matiaspoullain/Herramientas-cuantitativas-Contaminacion-aire-y-vehiculos/blob/main/Notebooks/4_Modelo_NO2_vehiculos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook 4: Modelado de la concentración de NO2 en función del conteo vehicular y variables meteorológicas\n",
        "##1.Librerías y datos\n",
        "Como en las notebooks anteriores, cargamos las librerías necesarias.\n",
        "\n",
        "Además, se descarga el repositorio de este práctico (https://github.com/matiaspoullain/Herramientas-cuantitativas-Contaminacion-aire-y-vehiculos) donde se encuentran todos los datos que se usarán.\n",
        "\n",
        "Corra las siguientes líneas de código. Puede demorar unos pocos minutos."
      ],
      "metadata": {
        "id": "0Ni2Q9PvNN_Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7_RkuLGgHkf"
      },
      "outputs": [],
      "source": [
        "## Instalado de versiones compatibles ##\n",
        "!pip uninstall fbprophet -y\n",
        "!pip install cmdstanpy==0.9.68\n",
        "!pip install pystan==2.19.1.1\n",
        "!pip install prophet\n",
        "\n",
        "## Carga de librerías ##\n",
        "from prophet import Prophet\n",
        "from prophet.utilities import regressor_coefficients\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime as dt\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "## Descarga del repositorio ##\n",
        "!git clone https://github.com/matiaspoullain/Herramientas-cuantitativas-Contaminacion-aire-y-vehiculos.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En primer lugar, cargamos los datos de NO2 y hacemos las transformaciones necesarias para poder utilizarlo luego como parte del input del modelo. Sus columnas son:\n",
        "\n",
        "\n",
        "1.   **ds**: Fecha de la medición\n",
        "2.   **y**: Concentración de NO2 troposférico (μmol.m$^{-2}$)\n",
        "\n"
      ],
      "metadata": {
        "id": "2TEvQqf7OMNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_no2 = pd.read_csv('Herramientas-cuantitativas-Contaminacion-aire-y-vehiculos/Datos/Buenos Aires_NO2trop_diario.csv')\n",
        "df_no2"
      ],
      "metadata": {
        "id": "s4KXG_w4hLLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_no2 = df_no2[df_no2['NO2_trop_mean'] <= 0.00025]\n",
        "df_no2 = df_no2[['Fecha_datetime', 'NO2_trop_mean']].rename(columns = {'Fecha_datetime': 'ds', 'NO2_trop_mean': 'y'})\n",
        "df_no2['ds'] = pd.to_datetime(df_no2['ds'], format = '%Y-%m-%d %H:%M:%S').dt.date\n",
        "\n",
        "df_no2 = df_no2.groupby(['ds']).agg({'y': 'mean'}).reset_index()\n",
        "\n",
        "df_no2"
      ],
      "metadata": {
        "id": "SkKU5SQNeSl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En segundo lugar, cargamos los datos de los vehículos. Este dataset requiere un poco más de manejo ya que la resolución temporal del conteo vehicular es horaria mientras que la de las mediciones de NO2 es diaria. Por esta razón agrupados los datos del conteo vehicular por día realizando una suma, obteniendo el conteo vehicular diario. Las columnas obtenidas son:\n",
        "\n",
        "1.   **ds**: Fecha del conteo\n",
        "2.   **precipitaciones**: Ocurrencia de precipitaciones (1: Ocurrencia, 0: No ocurrencia)\n",
        "3.   **temperatura**: Temperatura media del día (°C).\n",
        "4.   **vehiculos_observados**: Conteo diario de vehículos observado\n",
        "5.   **vehiculos_predichos**: Valor más probable del conteo diario de vehículos estimado por el modelo de la notebook anterior (100.000 vehiculos / día)\n",
        "6.   **vehiculos_predichos_min**: Valor mínimo del conteo diario de vehículos estimado por el modelo de la notebook anterior (100.000 vehiculos / día)\n",
        "7.   **vehiculos_predichos_max**: Valor máximo del conteo diario de vehículos estimado por el modelo de la notebook anterior (100.000 vehiculos / día)\n"
      ],
      "metadata": {
        "id": "zTWP8iaS5qG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_vehiculos = pd.read_csv(\"Herramientas-cuantitativas-Contaminacion-aire-y-vehiculos/Datos/df_prophet_prediccion.csv\")\n",
        "df_vehiculos['ds'] = pd.to_datetime(df_vehiculos['ds'], format = '%Y-%m-%d %H:%M:%S').dt.date\n",
        "\n",
        "df_vehiculos = df_vehiculos.groupby(['ds']).agg({'precipitaciones': 'sum',\n",
        "                                  'temperatura': 'mean',\n",
        "                                  'y': 'sum',\n",
        "                                  'yhat': 'sum',\n",
        "                                  'yhat_lower': 'sum',\n",
        "                                  'yhat_upper': 'sum'}).reset_index().rename(columns = {'y': 'vehiculos_observados',\n",
        "                                                                                        'yhat': 'vehiculos_predichos',\n",
        "                                                                                        'yhat_upper': 'vehiculos_predichos_max',\n",
        "                                                                                        'yhat_lower': 'vehiculos_predichos_min'})\n",
        "df_vehiculos.loc[df_vehiculos.precipitaciones > 0, 'precipitaciones'] = 1\n",
        "\n",
        "for i in ['vehiculos_observados', 'vehiculos_predichos', 'vehiculos_predichos_max', 'vehiculos_predichos_min']:\n",
        "  df_vehiculos[i] = df_vehiculos[i]/100000\n",
        "                                  \n",
        "df_vehiculos\n",
        "                                  "
      ],
      "metadata": {
        "id": "eyYQKmzujGGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unimos las bases de NO2 y vehiculos usando como columna común a **ds**. Esta nueva base será el input del modelo posterior."
      ],
      "metadata": {
        "id": "js78q5-B5w4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_no2_vehiculos = df_vehiculos.merge(df_no2, on = 'ds', how = \"left\")\n",
        "df_no2_vehiculos['ds'] = pd.to_datetime(df_no2_vehiculos['ds'])\n",
        "df_no2_vehiculos"
      ],
      "metadata": {
        "id": "bjF_1dFXkZPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Entrenamiento del modelo\n",
        "El modelo que implementaremos es nuevamente un modelo Prophet. La razón de utilizarlo es que estamos suponiendo que existen variables adicionales que influyen en la concentración de NO2 pero que no estamos incluyendo implícitamente en el modelo y que podrían ser agrupadas en las tendencias temporales que este tipo de modelo puede detectar, además de poder incluir variables explicativas adicionales.\n",
        "\n",
        "En este caso, también vamos a forzar una tendencia plana ya que la poca cantidad de años en la muestra no nos permitiría estimarla adecuadamente. Además buscaremos estacionalidades anuales y semanales. No podemos detectar estacionalidad diaria ya que la resolución de los datos no es sub-diaria. Por último, agregamos las variables explicativas adicionales: **precipitaciones**, **temperatura** y **vehiculos**.\n",
        "\n",
        "En el código, la variable **vehiculos** corresponde a **vehiculos_observados**. Fue necesario crear esa columna nueva para evitar confusiones más adelante.\n",
        "\n",
        "El entrenamiento del modelo puede demorar unos tres minutos."
      ],
      "metadata": {
        "id": "yyFx18lPUMOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(236343)\n",
        "\n",
        "df_no2_vehiculos['vehiculos'] = df_no2_vehiculos['vehiculos_observados'] #Se crea la variable \"vehiculos\" para evitar confusiones más adelante\n",
        "\n",
        "m = Prophet(growth = \"flat\",\n",
        "            yearly_seasonality = True,\n",
        "            daily_seasonality = False, #No se puede ajustar por la resolución de los datos\n",
        "            weekly_seasonality = True, #Si quiere comprobar que ocurre sin detección de estacionalidad semana puede cambiar True por False\n",
        "            mcmc_samples = 10000, #Cuanto más mejor pero tarda mucho...\n",
        "            seasonality_mode = \"additive\",\n",
        "            seasonality_prior_scale = 17.15802,\n",
        "            uncertainty_samples = 2000,\n",
        "            holidays_prior_scale = 0.4699147)\n",
        "\n",
        "m.add_regressor(\"precipitaciones\", mode = \"additive\") #Regresor precipitaciones\n",
        "m.add_regressor(\"temperatura\", mode = \"additive\") #Regresor temperatura\n",
        "m.add_regressor('vehiculos') #Regresor vehiculos. Si quiere comprobar que ocurre sin esta variable simplemente comente esta linea agreguando un # adelante\n",
        "\n",
        "m.fit(df_no2_vehiculos) "
      ],
      "metadata": {
        "id": "-7GEO8RPpbzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observamos los resultados del modelo:"
      ],
      "metadata": {
        "id": "8sTs9wAe504_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_no2_vehiculos['vehiculos'] = df_no2_vehiculos['vehiculos_observados']\n",
        "resultados = m.predict(df_no2_vehiculos)\n",
        "fig = m.plot_components(resultados)"
      ],
      "metadata": {
        "id": "8bdfXdrYo6fn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y los coeficientes estimados de las variables explicativas:"
      ],
      "metadata": {
        "id": "AHXgtCBPY0wM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coeficientes = regressor_coefficients(m)\n",
        "coeficientes"
      ],
      "metadata": {
        "id": "35gVsSbbrDjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 7))\n",
        "for lower, upper, center, y in zip(coeficientes['coef_lower'], coeficientes['coef_upper'], coeficientes['coef'], range(len(coeficientes))):\n",
        "  ax.plot((lower,upper),(y,y),'d-',color='orange')\n",
        "  ax.scatter(center, y, color='orange')\n",
        "plt.yticks(range(len(coeficientes)),list(coeficientes['regressor']))\n",
        "ax.axvline(x=0, linestyle = 'dashed')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3W7BAyWIrMru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   ¿Qué puede decir de las estacionalidades detectadas por el modelo?\n",
        "*   ¿Qué puede decir de las variables explicativas? ¿Cómo es su efecto estimado sobre la concentración de NO2?\n",
        "*   ¿Cómo hubiese esperado que cambien los resultados si no se agrega la variable explicativa **vehiculos**? Puede comprobarlo comentando el código con un # (`#m.add_regressor('vehiculos')`) y volver a correr el entrenamiento y los resultados.\n",
        "*   ¿Y si no se agrega una tendencia semanal? Puede comprobarlo cambiando `weekly_seasonality = True,` por `weekly_seasonality = False,`\n",
        "\n",
        "Antes de continar, asegúrese de volver a modificar los cambios que realizó en código del entrenamiento del modelo y volver a correrlo. De lo contrario, esos cambios serán arrastrados a lo largo de la notebook.\n",
        "\n",
        "##3. Predicciones con circulacion estimada\n",
        "En esta sección utilizaremos el modelo entrenado en la sección anterior en conjunto con el conteo vehicular estimado por el modelo Prophet de la notebook anterior. El objetivo es realizar una predicción de la concentración de NO2 troposférico desde el inicio de la cuarentena 2020 si la circulación vehicular mantenía la misma tendencia que la observada en fechas anteriores. Este este punto, estamos realizando la predicción de la concentración de NO2 troposférico si no hubiese habido cuarentena.\n",
        "\n",
        "En primer lugar, realizamos la predicción con este nuevo conjunto de datos. En este caso, la variable **vehiculos** es **vehiculos_predichos** y unimos las predicciones con las realizadas con **vehiculos_observados** en una misma tabla cuyas columnas corresponden a:\n",
        "1.   **ds**\n",
        "2.   **y**: Concentración troposférica de NO2 observada (μmol.m$^{-2}$)\n",
        "3.   Si contiene *prediccion_*: Concentración troposférica de NO2 predicha (μmol.m$^{-2}$)\n",
        "4.   Si contiene *_train*: Predicción utilizando el conteo vehicular observado\n",
        "5.   Si contiene *_test*: Predicción utilizando el conteo vehicular predicho\n",
        "6.   Si contiene *_max*: Valor máximo de la incerteza de la predicción\n",
        "7.   Si contiene *_min*: Valor mínimo de la incerteza de la predicción\n",
        "\n"
      ],
      "metadata": {
        "id": "BIac8jWXroDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_no2_vehiculos_test = df_no2_vehiculos.copy()\n",
        "df_no2_vehiculos_test['vehiculos'] = df_no2_vehiculos['vehiculos_predichos']\n",
        "resultados_test = m.predict(df_no2_vehiculos_test)\n",
        "\n",
        "resultados_train = resultados.copy()\n",
        "\n",
        "resultados_train['prediccion_train'] = resultados_train['yhat']\n",
        "resultados_train['prediccion_train_max'] = resultados_train['yhat_upper']\n",
        "resultados_train['prediccion_train_min'] = resultados_train['yhat_lower']\n",
        "\n",
        "\n",
        "resultados_test['prediccion_test'] = resultados_test['yhat']\n",
        "resultados_test['prediccion_test_max'] = resultados_test['yhat_upper']\n",
        "resultados_test['prediccion_test_min'] = resultados_test['yhat_lower']\n",
        "\n",
        "df_no2_vehiculos_predicciones = df_no2_vehiculos[['ds', 'y']].merge(resultados_train[['ds', 'prediccion_train', 'prediccion_train_max', 'prediccion_train_min']], on = 'ds').merge(resultados_test[['ds', 'prediccion_test', 'prediccion_test_max', 'prediccion_test_min']], on = 'ds')\n",
        "df_no2_vehiculos_predicciones\n"
      ],
      "metadata": {
        "id": "qAWnfP7rsp91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizamos el gráfico de las series de tiempo para observar más claramente las estimaciones:"
      ],
      "metadata": {
        "id": "mMb2L1j05y3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(30, 15))\n",
        "\n",
        "for i in ['train', 'test']:\n",
        "  predicho = 'prediccion_' + i\n",
        "  ax.plot(df_no2_vehiculos_predicciones['ds'], df_no2_vehiculos_predicciones[predicho], label='Predicho ' + i)\n",
        "  ax.plot(df_no2_vehiculos_predicciones['ds'], df_no2_vehiculos_predicciones[predicho + '_max'], color='tab:blue', alpha=0.1)\n",
        "  ax.plot(df_no2_vehiculos_predicciones['ds'], df_no2_vehiculos_predicciones[predicho + '_min'], color='tab:blue', alpha=0.1)\n",
        "  ax.fill_between(df_no2_vehiculos_predicciones['ds'], df_no2_vehiculos_predicciones[predicho + '_min'], df_no2_vehiculos_predicciones[predicho + '_max'], alpha=0.2, label='Incerteza ' + i)\n",
        "\n",
        "ax.scatter(df_no2_vehiculos_predicciones['ds'], df_no2_vehiculos_predicciones['y'], color='black', label='Observado')\n",
        "\n",
        "ax.axvline(x=dt.datetime(2020, 3, 20), color = 'black', linestyle = \"dashed\")\n",
        "\n",
        "ax.legend(loc=\"upper left\")\n",
        "ax.set_xlabel('Fecha')\n",
        "ax.set_ylabel('Concentración NO2 troposférico (umol.m-2)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pSfFRRpSwdl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   A simple vista y teniendo en cuenta la naturaleza ruidosa de la serie temporal del NO2, ¿son buenas las estimaciones? ¿Qué le llama la atención?\n",
        "*   ¿Son similares las predicciones entre *train* (a partir del conteo vehicular observado) y *test* (a partir del conteo vehicular predicho)? \n",
        "*   ¿Se mantiene la similaridad después del inicio de la cuarentena obligatoria (línea vertical punteada)?\n"
      ],
      "metadata": {
        "id": "exB759O06U1o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5. Estimación de la reducción de la concentración de NO2\n",
        "Finalmente, vamos a calcular la reducción de la concentración de NO2 troposférico comparando los predichos de *train* (Concentración de NO2 troposférico predicha utilizando al conteo vehicular observado) con los predichos de *test* (Concentración de NO2 troposférico predicha utilizando al conteo vehicular predicho):\n",
        "\n",
        "Para hacerlo, se calculará el promedio de la concentración de NO2 para un intervalo de tiempo específico y se calculará la proporción *promedio train*/*promedio test*. Es decir que:\n",
        "*   Proporción *promedio train*/*promedio test* ≈ 1 --> Predicciones de *train* y *test* similares\n",
        "*   Proporción *promedio train*/*promedio test* > 1 --> Predicciones de *train* mayores a las de *test*: Se esperaba menos NO2 del observado\n",
        "*   Proporción *promedio train*/*promedio test* < 1 --> Predicciones de *train* mayores a las de *test*: Se esperaba más NO2 del observado\n",
        "\n",
        "El siguiente código realiza los cálculos descriptos y muestra los resultados en tres gráficos de barras:\n",
        "1.   Comparación de *promedio train* y *promedio test* dentro de cada intervalo de tiempo. Las barras de error representan el intervalo de incerteza\n",
        "2.   Comparación de *promedio train* y *promedio test* entre intervalos de tiempo. Las barras de error representan el intervalo de incerteza\n",
        "3.   Proporción *promedio train*/*promedio test* para cada intervalo de tiempo. Estos resultados tambien muestran en una tabla\n",
        "\n",
        "Modifique el objeto `intervalos` para comparar distintos intervalos de tiempo entre sí. Este objeto debe tener el siguiente formato:\n",
        "\n",
        "\n",
        "\n",
        "```python\n",
        "intervalos = [[fecha_inicial_1, fecha_final_1],\n",
        "              [fecha_inicial_2, fecha_final_2],\n",
        "              [fecha_inicial_3, fecha_final_3],\n",
        "              ...\n",
        "              [fecha_inicial_n, fecha_final_n]]\n",
        "```\n",
        "Donde cada par `[fecha_inicial_n, fecha_final_n]` representa un intervalo de tiempo y cada fecha sigue el formato 'YYYY-MM-DD'.\n"
      ],
      "metadata": {
        "id": "V4lc--Uc5iiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### Modifique las siguientes líneas de código #####\n",
        "intervalos = [['2019-01-01', '2020-03-20'],\n",
        "              ['2020-04-01', '2020-05-01'],\n",
        "              ['2020-05-01', '2020-06-01'],\n",
        "              ['2020-06-01', '2020-07-01'],\n",
        "              ['2020-07-01', '2020-08-01'],\n",
        "              ['2020-08-01', '2020-09-01']]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##### NO modifique las siguientes líneas de código #####\n",
        "df_final = pd.DataFrame()\n",
        "for i in intervalos:\n",
        "  df_it = df_no2_vehiculos_predicciones[(df_no2_vehiculos_predicciones['ds'] >= i[0]) & (df_no2_vehiculos_predicciones['ds'] <= i[1])]\n",
        "  df_it = df_it.agg({'prediccion_train': 'mean',\n",
        "                     'prediccion_test': 'mean',\n",
        "                     'prediccion_train_max': 'mean',\n",
        "                     'prediccion_test_max': 'mean',\n",
        "                     'prediccion_train_min': 'mean',\n",
        "                     'prediccion_test_min': 'mean'}).reset_index().rename(columns = {'index': 'prediccion',\n",
        "                                                                                  0: 'area'})\n",
        "  df_it['intervalo'] = str(i)\n",
        "  df_final = df_final.append(df_it)\n",
        "\n",
        "df_final['train_test'] = np.where(df_final['prediccion'].str.contains('train'), 'train', 'test')\n",
        "df_final = df_final.groupby(['intervalo', 'train_test']).agg(medio = ('area', 'median'),\n",
        "                                                  minimo = ('area', 'min'),\n",
        "                                                  maximo = ('area', 'max')).reset_index()\n",
        "\n",
        "#print(df_final)\n",
        "\n",
        "df_final_wide = df_final.pivot(index = 'intervalo', columns = 'train_test', values = ['medio', 'minimo', 'maximo']).reset_index()\n",
        "df_final_wide.columns = [\"_\".join(a) for a in df_final_wide.columns.to_flat_index()]\n",
        "for i in ['medio']:#, 'minimo', 'maximo']:\n",
        "  df_final_wide[i + '_train_test'] = df_final_wide[i + '_train'] / df_final_wide[i + '_test']\n",
        "\n",
        "#df_final_wide['minimo_train_test'] = df_final_wide['medio_train_test'] - df_final_wide['minimo_train_test']\n",
        "#df_final_wide['maximo_train_test'] = df_final_wide['maximo_train_test'] - df_final_wide['medio_train_test']\n",
        "\n",
        "#Graficos:\n",
        "def func(x,y,h,lb,ub, **kwargs):\n",
        "    data = kwargs.pop(\"data\")\n",
        "    # from https://stackoverflow.com/a/37139647/4124317\n",
        "    errLo = data.pivot(index=x, columns=h, values=lb)\n",
        "    errHi = data.pivot(index=x, columns=h, values=ub)\n",
        "    err = []\n",
        "    for col in errLo:\n",
        "        err.append([errLo[col].values, errHi[col].values])\n",
        "    err = np.abs(err)\n",
        "    p = data.pivot(index=x, columns=h, values=y)\n",
        "    p.plot(kind='bar',yerr=err,ax=plt.gca(), **kwargs)\n",
        "\n",
        "fig, axs = plt.subplots(ncols=3, figsize=(25, 12))\n",
        "\n",
        "plt.sca(axs[0])\n",
        "func(\"intervalo\", \"medio\", \"train_test\", \"minimo\", \"maximo\", data=df_final)\n",
        "plt.title(\"1. Comparación entre train-test\")\n",
        "plt.ylabel(\"Concentración NO2 troposférico promedio (umol.m-2)\")\n",
        "plt.xlabel(\"Intervalo\")\n",
        "axs[0].tick_params(labelrotation=45)\n",
        "\n",
        "plt.sca(axs[1])\n",
        "func(\"train_test\", \"medio\", \"intervalo\", \"minimo\", \"maximo\", data=df_final)\n",
        "plt.title(\"2. Comparación entre intervalos\")\n",
        "plt.ylabel(\"Concentración NO2 troposférico promedio (umol.m-2)\")\n",
        "plt.xlabel(\"Predicción\")\n",
        "axs[1].tick_params(labelrotation=45)\n",
        "\n",
        "plt.sca(axs[2])\n",
        "sns.barplot(x=\"intervalo_\", y=\"medio_train_test\", data=df_final_wide)\n",
        "plt.title(\"3. Proporción promedio train/promedio test\")\n",
        "plt.ylabel(\"Proporción\")\n",
        "plt.xlabel(\"Intervalo\")\n",
        "axs[2].tick_params(labelrotation=45)\n",
        "\n",
        "df_final_wide['reduccion'] = round(100*(1-df_final_wide['medio_train_test']), 2)\n",
        "\n",
        "df_final_wide[['intervalo_', 'medio_train_test', 'reduccion']].rename(columns = {'intervalo_': 'Intervalo',\n",
        "                                                                    'medio_train_test': 'Proporción promedio train/promedio test',\n",
        "                                                                    'reduccion': 'Reducción (%)'})"
      ],
      "metadata": {
        "id": "K6Nbpt4m7tmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   ¿Fueron similares las estimaciones de *train* y *test* antes de la cuarentena?\n",
        "*   ¿Cuanto se redujo el NO2 en la cuarentena?\n",
        "*   ¿Hubo diferencias de la reducción el los distintos meses durante la cuarentena? ¿Cuál fue el mes con mayor reducción?\n",
        "\n",
        "##6. Conclusión\n",
        "En esta notebook se buscó cuantificar la diferencia entre la concentración de NO2 troposférico observado en el 2020 y el esperado de no haber habido cuarentena por COVID-19. Sabiendo que el valor real nunca podría ser medido fehacientemente, se realizaron distintos modelos para tratar de imitar de la forma más fiel posible el comportamiento del NO2 y así reconstruir un escenario hipotético. \n",
        "\n",
        "Pudimos observar que la ocurrencia de precipitaciones y el conteo vehicular son variables importantes para explicar la concentración troposférica de NO2. En concordancia con la bibliografía, a ocurrencia de lluvias el NO2 es menor y a mayor circulación vehicular mayor NO2. Sin embargo, el comportamiento de la concentración de este gas es muy erratico, ya sea por errores de medición o por otros factores no incluídos en este análsis. Sin embargo, con solo dos variables adicionales, pudimos estimar que la concentración de NO2 troposférico que se redujo en el 2020 pero que esta reducción no fue constante en el tiempo. El mes con la mayor reducción fue abril, con un 30%, mientras que en diciembre fue del 9%.\n",
        "\n",
        "Está claro que la concentración de NO2 no esta definida por la circulación vehicular y la occurrencia de precipitaciones, por lo que, a fin de mejorar los resultados obtenidos, es necesario incorporar otras variables que podrían estar involucradas, como la intensidad y dirección de los vientes troposféricos y otras actividades industriales y comerciales que emiten en gas, además de mediciones más precisas in situ.\n",
        "\n",
        "# Preguntas de evaluación:\n",
        "Entre al siguiente formulario, léalo atentamente y responda a las preguntas de evaluación en base a lo evidenciado en esta notebook:\n",
        "\n",
        "https://forms.gle/NqiepZbHeZUtycV3A"
      ],
      "metadata": {
        "id": "4A3wN7enJ7fs"
      }
    }
  ]
}